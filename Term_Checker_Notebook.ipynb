{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Urban Resilience Metric - Term lookup\n",
        "This notebook aims to find words that correspond to the City Resilience Index(https://www.cityresilienceindex.org/#/city-profiles). The notebook uses Hugging Face - sentence transformers as part of the main method: https://huggingface.co/docs/hub/sentence-transformers It pulls unigram / bigram, search for top 100 terms using the 5 pdf provided. Using the result, we come up with listing of words we will use to compare to cities to result an urban resilience metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0UGTl67tb2A6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in c:\\users\\lifet\\anaconda3\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: torchvision in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: nltk in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.0.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.16.4)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.31.0)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: numpy in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scipy in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2022.2.0)\n",
            "Requirement already satisfied: requests in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: networkx in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.11.3)\n",
            "Requirement already satisfied: sympy in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.0.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (10.0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\lifet\\anaconda3\\lib\\site-packages (2.0.1)\n",
            "Requirement already satisfied: torchvision in c:\\users\\lifet\\anaconda3\\lib\\site-packages (0.15.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
            "Requirement already satisfied: requests in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torchvision) (10.0.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\lifet\\anaconda3\\lib\\site-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: click in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Requirement already satisfied: pdfplumber in c:\\users\\lifet\\anaconda3\\lib\\site-packages (0.10.2)\n",
            "Requirement already satisfied: Pillow>=9.1 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from pdfplumber) (10.0.0)\n",
            "Requirement already satisfied: pdfminer.six==20221105 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from pdfplumber) (20221105)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from pdfplumber) (4.18.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (41.0.3)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (2.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.0)\n",
            "Requirement already satisfied: pycparser in c:\\users\\lifet\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\lifet\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install torch torchvision\n",
        "!pip install nltk\n",
        "!pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C0xV9-L1cx56"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pdfplumber\n",
        "import re\n",
        "import string\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to\n",
            "[nltk_data]     C:\\Users\\lifet\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\lifet\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\lifet\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download necessary data for nltk\n",
        "nltk.download([\"names\", \"stopwords\", \"punkt\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Define the model and check if GPU is available. If yes, move the model to GPU.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SentenceTransformer('all-mpnet-base-v2').to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7VWHn7FQmNCV"
      },
      "outputs": [],
      "source": [
        "# Extract text from pdf file\n",
        "import pdfplumber\n",
        "files = [\"D:\\Graduate School\\Experience Expo\\Code\\Report PDF/Cali-Resilience-Strategy-English.pdf\",\n",
        "         \"D:\\Graduate School\\Experience Expo\\Code\\Report PDF/Cape-Town-Resilience-Strategy-English.pdf\",\n",
        "         \"D:\\Graduate School\\Experience Expo\\Code\\Report PDF/Pune-Resilience-Strategy-English.pdf\",\n",
        "         \"D:\\Graduate School\\Experience Expo\\Code\\Report PDF/Seattle-Resilience-Strategy-English.pdf\",\n",
        "         \"D:\\Graduate School\\Experience Expo\\Code\\Report PDF/Surat-Resilience-Strategy-English.pdf\"] # Upload required pdfs and add paths to the list\n",
        "\n",
        "# Initialize an empty string to store extracted text from all PDFs\n",
        "text = \"\"\n",
        "\n",
        "# Extract text from each PDF and append to the 'text' string\n",
        "for filepath in files:\n",
        "    with pdfplumber.open(filepath) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += \" \" + page.extract_text()\n",
        "\n",
        "# Convert the text to lowercase for consistency\n",
        "text = text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ujRqBonQyk8I"
      },
      "outputs": [],
      "source": [
        "# Function to clean the text\n",
        "def clean_text(text):\n",
        "    # Remove numbers\n",
        "    text_nonum = re.sub(r'\\d+', '', text)\n",
        "    # Remove punctuation and convert to lowercase\n",
        "    text_nopunct = \"\".join([char.lower() for char in text_nonum \n",
        "                            if char not in string.punctuation])\n",
        "    # Remove any multiple spaces\n",
        "    text_no_doublespace = re.sub('\\s+', ' ', text_nopunct).strip()\n",
        "    return text_no_doublespace\n",
        "\n",
        "# Clean the aggregated text\n",
        "text = clean_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sRJ11LLOdpTf"
      },
      "outputs": [],
      "source": [
        "# Define a list of indicators and compute embeddings for them\n",
        "indicator_list = [\"Effective co-ordination\",\"government authorities\", \"government co-ordination\"]\n",
        "indicator_embeddings = [torch.tensor(model.encode(indicator)).to(device) for indicator in indicator_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBgKHJy-oGCK",
        "outputId": "62e1423c-0763-41de-8981-4b7104afbf83"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text and generate a list of unigrams (individual words) and bigrams (pairs of words)\n",
        "raw_words: list[str] = nltk.word_tokenize(text)\n",
        "words = [w.lower() for w in raw_words if w.isalpha()]\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "words = [w for w in words if w not in stopwords and len(w) > 3]\n",
        "\n",
        "text_new = nltk.Text(words)\n",
        "finder_unigram = text_new.vocab()\n",
        "finder_bigram = nltk.collocations.BigramCollocationFinder.from_words(raw_words)\n",
        "\n",
        "# Initialize a list to store words/phrases and their relevance scores\n",
        "scored_words = []\n",
        "\n",
        "# Compute the relevance of each unigram by comparing its embedding to the embeddings of the indicators\n",
        "for word, freq in finder_unigram.items():\n",
        "    word_emb = torch.tensor(model.encode(word)).to(device)  # Convert to PyTorch tensor and move to device\n",
        "    for indicator_emb in indicator_embeddings:\n",
        "        s = (indicator_emb * word_emb).sum()  # Dot product using PyTorch tensors\n",
        "        scored_words.append((s.item(), word))  # Convert tensor to scalar using .item()\n",
        "\n",
        "# Compute the relevance of each bigram by comparing its embedding to the embeddings of the indicators\n",
        "for word, freq in finder_bigram.ngram_fd.items():\n",
        "    sentence = \" \".join(word)\n",
        "    word_emb = torch.tensor(model.encode(sentence)).to(device)  # Convert to PyTorch tensor and move to device\n",
        "    for indicator_emb in indicator_embeddings:\n",
        "        s = (indicator_emb * word_emb).sum()  # Dot product using PyTorch tensors\n",
        "        scored_words.append((s.item(), sentence))  # Convert tensor to scalar using .item()\n",
        "\n",
        "# Sort the scored words/phrases in descending order of relevance\n",
        "scored_words.sort(reverse=True)\n",
        "\n",
        "# Print the top 100 most relevant terms\n",
        "for score, word in scored_words[:100]:\n",
        "    print(word, score)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
